{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The basic sequence-to-sequence model\n",
    "Here you'll be implementing the most basic sequence-to-sequence model. Consists of two GRUs and a classification layer (as well as one embedding layer for each source and target vocabularies).\n",
    "\n",
    "There will be a lot hyperparameters, so it will be convenient to pass an option variable (that stores all hyperparamters) to the constructor when calling them. Similar to what you've done with the params.json file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder \n",
    "The encoder transforms the source input sequence into features that is passed to the decoder for generating a sequence.\n",
    "\n",
    "### Homework\n",
    "Write a module for the encoder\n",
    "1. Takes in srcBatch == (German word indices, GERMAN_original_lengths ) as input\n",
    "2. Consists of \n",
    "    - Embedding layer\n",
    "    - Bi-directional, 1 layer GRU, use packed sequence\n",
    "3. The encoder outputs the GRU output, and its last hidden state. \n",
    "4. The encoder output has dimension ~ [B,S,2*D_enc], where D_enc is the output dimension of the GRU, the factor of two comes from the two directions (you don't need to do anything to get 2*D_enc). The last hidden state has dimensions [2,B,D_enc].\n",
    "\n",
    "Even though we will only use the GRU's last hidden state, and not its output, we keep it in the encoder output for now. We will be using the output when we start using the attention mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Att(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.p = torch.nn.Parameter(torch.rand(1,4,5))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f(*args):\n",
    "    return args[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(4, 5, 5)\n",
    "y = torch.rand(1, 4, 5)\n",
    "z = torch.rand(10, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = torch.tensor([[[1,2],[3,4]]])\n",
    "b = torch.tensor([[10,0],[0,10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[10,  0],\n",
       "         [ 0, 40]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L = []\n",
    "y_1 = y\n",
    "for i in range(x.shape[1]):\n",
    "    out, y = g(x[:,i:i+1,:], y)\n",
    "    L.append(out)\n",
    "b = torch.cat(L, dim=1)\n",
    "\n",
    "a, h = g(x, y_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 5, 5]), torch.Size([1, 4, 5]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape, h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b - a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1493, -0.3334,  0.2257, -0.0451, -0.0450],\n",
       "         [ 0.1625, -0.3466,  0.2309, -0.0137, -0.0020],\n",
       "         [ 0.1940, -0.3031,  0.2657,  0.0224,  0.0411],\n",
       "         [ 0.1307, -0.3988,  0.2248, -0.0576, -0.0237],\n",
       "         [ 0.1050, -0.4080,  0.2241, -0.1063, -0.0689]],\n",
       "\n",
       "        [[ 0.1397, -0.4140,  0.2234,  0.0087,  0.1228],\n",
       "         [ 0.1276, -0.4129,  0.2084,  0.0831,  0.0670],\n",
       "         [ 0.1678, -0.3154,  0.2277,  0.0360,  0.0652],\n",
       "         [ 0.0765, -0.4434,  0.2526, -0.0589,  0.0045],\n",
       "         [ 0.1137, -0.3908,  0.2221, -0.0983,  0.0361]],\n",
       "\n",
       "        [[ 0.0646, -0.3752,  0.3508, -0.1250,  0.0646],\n",
       "         [ 0.0869, -0.3480,  0.3156, -0.0587,  0.0016],\n",
       "         [ 0.0392, -0.4347,  0.3001, -0.1704,  0.0179],\n",
       "         [ 0.1090, -0.4263,  0.2620, -0.0398,  0.1505],\n",
       "         [ 0.0754, -0.4265,  0.3009, -0.0909,  0.1143]],\n",
       "\n",
       "        [[ 0.1675, -0.3646,  0.3311,  0.0877,  0.2010],\n",
       "         [ 0.1769, -0.3078,  0.3357,  0.0359,  0.1372],\n",
       "         [ 0.1533, -0.3725,  0.3445,  0.0602,  0.1665],\n",
       "         [ 0.2157, -0.3118,  0.2911,  0.0701,  0.2104],\n",
       "         [ 0.1288, -0.4056,  0.3276, -0.0623,  0.1564]]],\n",
       "       grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[0.3234, 0.2675, 0.3116, 0.3432, 0.5607]],\n",
       " \n",
       "         [[0.1133, 0.1946, 0.6486, 0.4176, 0.2496]]],\n",
       "        grad_fn=<TransposeBackward0>),\n",
       " tensor([[[ 0.2260,  0.0588,  0.2708,  0.3016,  0.2143]],\n",
       " \n",
       "         [[ 0.0861,  0.1145,  0.4533,  0.0516, -0.0155]]],\n",
       "        grad_fn=<TransposeBackward0>),\n",
       " tensor([[[ 0.1294, -0.0170,  0.3525,  0.0330, -0.0804]],\n",
       " \n",
       "         [[-0.0727, -0.0591,  0.3707, -0.1014, -0.2206]]],\n",
       "        grad_fn=<TransposeBackward0>)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_1 = y.reshape(1, -1, 10)\n",
    "y_2 = y.reshape(1, 2, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_1 == y_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.3013,  0.5212,  0.5297,  0.4256,  0.1757, -0.1173,  0.2165,\n",
       "           -0.0381,  0.3361,  0.0966]],\n",
       " \n",
       "         [[ 0.6927,  0.3957,  0.2995,  0.3448,  0.4576, -0.1258,  0.1210,\n",
       "           -0.0139,  0.3930,  0.2677]]], grad_fn=<TransposeBackward0>),\n",
       " tensor([[[ 0.3013,  0.5212,  0.5297,  0.4256,  0.1757],\n",
       "          [ 0.6927,  0.3957,  0.2995,  0.3448,  0.4576]],\n",
       " \n",
       "         [[-0.1173,  0.2165, -0.0381,  0.3361,  0.0966],\n",
       "          [-0.1258,  0.1210, -0.0139,  0.3930,  0.2677]]],\n",
       "        grad_fn=<StackBackward>))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "g(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.0172,  0.3889,  0.2774,  0.3145,  0.2928, -0.1933, -0.0536,\n",
       "           -0.0997,  0.4987,  0.3862]],\n",
       " \n",
       "         [[ 0.0598,  0.5259,  0.2992,  0.1735,  0.2973, -0.0458, -0.1524,\n",
       "            0.2355,  0.4287,  0.1915]]], grad_fn=<TransposeBackward0>),\n",
       " tensor([[[-0.0172,  0.3889,  0.2774,  0.3145,  0.2928],\n",
       "          [ 0.0598,  0.5259,  0.2992,  0.1735,  0.2973]],\n",
       " \n",
       "         [[-0.1933, -0.0536, -0.0997,  0.4987,  0.3862],\n",
       "          [-0.0458, -0.1524,  0.2355,  0.4287,  0.1915]]],\n",
       "        grad_fn=<StackBackward>))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder\n",
    "Rather than inputting the whole sequence as in the encoder, we pick word indices from tgtBatch at time $t$ and loop through $t$. The output of the decoder is the conditional log-likelihood of each word. \n",
    "\n",
    "$\\log p(y_t | y_{0:t-1}, s_{t-1})$, \n",
    "\n",
    "where $y_t$ is the t-th word and $s_{t-1}$ is the last hidden state from the last time step. At $t=0$, $s_0 = h_S$, where $h_S$ is the last hidden state from the **encoder**. In other words the task is to predict the next word given a partial sentence. \n",
    "\n",
    "The steps to implement this are:\n",
    "\n",
    "1. Write a decoder module just as you would for the encoder. (this homework)\n",
    "2. Once you have a decoder module, pick out the $t$-th word indices from tgtBatch and use this as the decoder input. Keep track of the last decoder hidden state $s_t$ from the GRU. (next homework)\n",
    "3. Loop through $t$, (next homework).\n",
    "\n",
    "We don't need to use packed sequences here, as we are passing batches of tokens (length 1) step by step. The padding are taken care of by masking the loss function.\n",
    "\n",
    "### Homework\n",
    "Write a module for the decoder, without the classification layer\n",
    "1. Takes in tgtBatch == (English word indices, ENGLISH_original_lengths) as input\n",
    "2. Consists of \n",
    "    - Embedding layer\n",
    "    - Uni-directional, 1 layer GRU, **do not** use packed sequence\n",
    "3. The decoder outputs the GRU output, and its last hidden state. \n",
    "4. We will add the classification layer in the loop over $t$, outside of this module.\n",
    "\n",
    "The decoder output has dimension ~ [B,T,D_dec], where D_dec = 2*D_enc. The last hidden state has dimensions [1,B,D_dec]. The output dimension of the decoder D_dec is fixed by the encoder output dimension, because we wlil be using the encoder's last hidden state as the decoder's last hidden state for $t=0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Insert code here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting everything together\n",
    "Here, you will put the encoder and decoder module together, put the decoder in a loop over $t$, as well as adding a classification layer on top, to form the sequence-to-sequence model.\n",
    "\n",
    "### The loss function\n",
    "The loss function is the log-joint-likelihood of the sequence\n",
    "\n",
    "$L = \\sum_{t=0}^{T-1}  \\log p(y_t | y_{0:t-1}, s_{t-1})$,\n",
    "\n",
    "i.e. the sum of cross entropy loss over time. For the implementation, you have to pass the argument ignore_index=0 to the CrossEntropyLoss constructor. It tells Pytorch to ignroe the padded indices (presumably 0) by masking. You may also need to set reduction='None' to stop Pytorch from taking the mean over batches (by default) before summing over $t$. \n",
    "\n",
    "See the options for the CrossEntropyLoss module:\n",
    "https://pytorch.org/docs/stable/nn.html#torch.nn.CrossEntropyLoss\n",
    "\n",
    "### Training method - Teacher Forcing\n",
    "We input the known target word as input during training, rather than using the previous predicted word as input. This is to stabilize training in the early stages. However it causes *exposure bias*, as the training operation is not the same as the sequence generation operation, where the previous word is used as input. This method is called **teacher forcing**.\n",
    "\n",
    "### Homework\n",
    "1. Write a Seq2Seq module, that takes in a tuple (srcBatch, tgtBatch), and outputs the log-joint-likelihood, summed over all $t$ on the target batch. If you are confused about how to do the time loop, look at the code at the end of the notebook for an idea. Half of which is relevant. \n",
    "\n",
    "\n",
    "2. Attributes of the Seq2Seq module class contain (but not limited to)\n",
    "    - self.encoder = ...\n",
    "    - self.decoder = ...\n",
    "    - self.lossLayer = ...    \n",
    "\n",
    "\n",
    "3. The forward function in the module class has the following order:\n",
    "    1. Get the output and last hidden state, h, from the encoder, the dimensions should be output ~ [B,S,D_enc], h ~ [ 2,B,D_enc].\n",
    "       \n",
    "    2. Set initial decoder last_state to be $h$, concatenating the two directions, you'll need to reshape h to [1,B,2*D_enc].\n",
    "    \n",
    "    3. Loop through t:\n",
    "        - Get decoder_input **from tgtBatch** at time t, decoder input ~ [B,1], a sequence of length 1.\n",
    "        - Get decoder_output, next_state from self.decoder(decoder_input, last_state)\n",
    "        - Get loss_t at time t from the classification layer followed by softmax.\n",
    "        - Accumulate loss_t over t\n",
    "        - set last_state = next_state\n",
    "\n",
    "    4. The loss function is the sum over all loss_t over t, average this over the batch.\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Insert code here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "At this stage, you should have a module that outputs the loss tensor given a batch of source and target sequences. Then training proceeds as usual, calling backward() on the loss...etc. \n",
    "\n",
    "### Homework\n",
    "Train the model, print out the training and validation loss. Note that we're still using "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Insert code here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus: Greedy search, example\n",
    "The simplest way to generate a sequence is the greedy search, which only picks the most likely word in each time step.\n",
    "\n",
    "We cannot use the previous code for training because now the decoder input is the previous generated word, and not the ground truth which we have no access to.\n",
    "\n",
    "A pseudo code of the greedy search method is below. When we do beam search the code follows a similar structure. The translator class object is defined right after the model declaration, e.g.\n",
    "\n",
    "model = Net(hyperparameters)\n",
    "\n",
    "translator = Translator(hyperparameters, model)\n",
    "\n",
    "The model being passed here is actually a reference to the model (and its parameters). So we can use the translator object to generate sequence during training.\n",
    "\n",
    "In the code below, I did a few things other than just picking out the best words\n",
    "- Forcing the sequence to generate the EOS token whenever the previous word is EOS.\n",
    "- Termination condition, when all sequences in the batch ends with EOS.\n",
    "\n",
    "The function translate() returns the generated indices in the batch. The (inverse) dictionary word2idx is used to translate it back to real words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import beam_search\n",
    "\n",
    "#Pseudo code for translation, most likely have bugs.\n",
    "class Translator(object):\n",
    "    def __init__(self,hp,model):\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "        self.hp = hp #hyperparameters\n",
    "        \n",
    "    def translate(self, srcBatch, tgtBatch,EOS=2): #we only target batch for evaluation scores (e.g. BLEU)\n",
    "        B = srcBatch[0].shape[0]\n",
    "        \n",
    "        #  (1) run the encoder on the src\n",
    "        x  , h = self.model.encoder(srcBatch) #h ~ [2,B,D_enc]\n",
    "\n",
    "        #initializing with <sos> tokens, [B]\n",
    "        translation = torch.tensor(tgtBatch[0][:,t])\n",
    "        #Initializaing EOS_indices to be an empty set\n",
    "        EOS_indices = []        \n",
    "        #Initializing decoder input.\n",
    "        dec_in = tgtBatch[0][:,t].unsqueeze(1) #all SOS tokens\n",
    "        #Initializing last decoder state, reshaping h to [1,B,2D_enc]\n",
    "        last_state = h.transpose(1,0).reshape(1,B,2*h.shape[-1]).transpose(1,0).contiguous()\n",
    "\n",
    "        #  (2) loop through decoder t        \n",
    "        for t in range(self.hp.T_dec):\n",
    "            \n",
    "            #Model operations\n",
    "            dec_out, last_state = self.model.decoder(dec_in, last_state)\n",
    "            logit = self.model.classifier(dec_out) #logit ~ [B,vocab_size]\n",
    "            \n",
    "            #Greedy Search\n",
    "            next_words = logit.argmax(dim=1) #picking the best word, [B]\n",
    "            \n",
    "            #Forcing EOS if previous word is EOS as well\n",
    "            next_words[EOS_indices] = EOS\n",
    "            \n",
    "            # Termination condition\n",
    "            if all(next_words==EOS): break\n",
    "            \n",
    "            #setting up for next time step.\n",
    "            EOS_indices = next_words.eq(EOS).nonzero() #this will be used to force EOS in the next time step\n",
    "            dec_in = next_words #using generated words for next decoder input\n",
    "            \n",
    "            #Stacking chosen words to [B,t]\n",
    "            translation = torch.stack([translation,next_words])\n",
    "        return translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
